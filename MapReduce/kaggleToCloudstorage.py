# -*- coding: utf-8 -*-
"""UploadFilesFromKaggleToCloudStorage.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Pb4L5_sHe6gYhBI9ia9ExS2LoqYWeV9d
"""

! pip install -q kaggle

!pip install --upgrade --force-reinstall --no-deps kaggle

from google.colab import files

files.upload()

! mkdir ~/.kaggle

!cp kaggle.json ~/.kaggle/

! chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d mkechinov/ecommerce-behavior-data-from-multi-category-store

! unzip ecommerce-behavior-data-from-multi-category-store.zip -d dataset

from google.colab import auth
auth.authenticate_user()

project_id = 'bamboo-case-331602'
!gcloud config set project {project_id}
!gsutil ls

bucket_name = 'proyecto-dba-ccn'
!gsutil -m cp -r /content/dataset/* gs://{bucket_name}/

import csv
import firebase_admin
import google.cloud
from firebase_admin import credentials, firestore

cred = credentials.Certificate("./ServiceAccountKey.json")
app = firebase_admin.initialize_app(cred)

store = firestore.client()

file_path = "/content/dataset/2019-Nov.csv"
collection_name = "eCommerce"

def batch_data(iterable, n=1):
    l = len(iterable)
    for ndx in range(0, l, n):
      yield iterable[ndx:min(ndx + n, l)]

data = []
headers = []
with open(file_path) as csv_file:
    csv_reader = csv.reader(csv_file, delimiter=',')
    line_count = 0
    for row in csv_reader:
        if line_count == 0:
            for header in row:
              headers.append(header)
            line_count += 1
        else:
            obj = {}
            for idx, item in enumerate(row):
              obj[headers[idx]] = item
            data.append(obj)
            line_count += 1
    print(f'Processed {line_count} lines.')

for batched_data in batch_data(data, 499):
    batch = store.batch()
    for data_item in batched_data:
        doc_ref = store.collection(collection_name).document()
        batch.set(doc_ref, data_item)
    batch.commit()



